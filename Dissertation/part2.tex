\chapter{Теоретические основы метода HolUE}
\label{chap:theory}

В данной главе мы подробно изложим теоретические основы метода \textit{HolUE} (Holistic Uncertainty Estimation), который представляет собой комплексную оценку неопределенности в задаче открытого распознавания. Метод основан на байесовской модели, которая объединяет два независимых источника неопределенности: неопределенность, связанную с качеством входного сигнала (эмбеддинга), и неопределенность, обусловленную структурой галереи известных объектов. В этой главе мы последовательно опишем формальную постановку задачи OSR, затем представим метод \textit{GalUE} (Gallery-Aware Uncertainty Estimation) как способ оценки неопределенности, обусловленной структурой галереи, и метод \textit{SCF} (Spherical Confidence Face) как способ оценки неопределенности, связанной с качеством сигнала. Наконец, мы объединим эти два метода в единый фреймворк \textit{HolUE}, который позволяет вычислять комплексную меру неопределенности.

\section{Формальная постановка задачи открытого распознавания}
\label{sec:osr_formulation}

Задача открытого распознавания (Open-Set Recognition, OSR) заключается в том, чтобы система могла не только идентифицировать объекты, присутствующие в заранее заданной галерее известных объектов, но и отвергать объекты, не принадлежащие ни одному из этих классов. Формально, пусть у нас есть галерея $G = \{g_1, ..., g_K\}$, состоящая из $K$ шаблонов, каждый из которых соответствует одному из $K$ известных классов. При поступлении пробного образца $p = \{x_1, ..., x_m\}$ (в большинстве случаев $m=1$) система должна ответить на два вопроса:
\begin{enumerate}
    \item Существует ли в галерее $G$ шаблон, соответствующий пробному образцу $p$? Если да, то какой именно?
    \item Если такой шаблон существует, то каков его идентификатор $\hat{i}(g^*) \in \{1, ..., K\}$?
\end{enumerate}

Если система принимает решение, что пробный образец $p$ принадлежит одному из известных классов, он классифицируется, в противном случае он отвергается как несоответствующий ни одному из классов галереи. Для решения этой задачи системы OSR обычно используются детерминированные или вероятностные эмбеддинги, которые представляют объекты в пространстве признаков. В дальнейшем мы будем использовать следующие обозначения:
\begin{itemize}
    \item $x$ — входной сигнал (изображение, звук и т.д.).
    \item $z$ — эмбеддинг, полученный из сигнала $x$.
    \item $c$ — метка класса ($c \in \{1, ..., K\}$ для галереи, $c \in (K, K+1]$ для out-of-gallery класса).
    \item $\mu_c$ — средний эмбеддинг класса $c$.
    \item $\kappa_x$ — концентрация эмбеддинга $z$ для сигнала $x$ (мера качества сигнала).
\end{itemize}

\section{Метод GalUE: Оценка неопределенности, обусловленной структурой галереи}
\label{sec:galue}

Метод \textit{GalUE} (Gallery-Aware Uncertainty Estimation) — это байесовская модель, которая позволяет оценить неопределенность, связанную с относительным положением эмбеддинга пробного образца в пространстве галереи. Эта модель предполагает, что эмбеддинг $z$ является детерминированным и вычисляется с помощью предварительно обученной модели (например, ArcFace~\cite{deng2019arcface}). Целью GalUE является вычисление апостериорного распределения классов $p(c|z)$, которое показывает, насколько вероятно, что эмBEDдинг $z$ принадлежит каждому из классов, включая out-of-gallery класс.

Для построения этой модели мы используем правило Байеса:
\begin{equation}
p(c|z) = \frac{p(z|c)p(c)}{p(z)},
\label{eq:bayes_rule}
\end{equation}
где $p(c)$ — априорное распределение классов, $p(z|c)$ — условное распределение эмбеддинга при заданном классе, а $p(z)$ — маргинальное распределение эмбеддинга.

\subsection{Априорное распределение классов}
\label{subsec:prior}

Априорное распределение $p(c)$ моделирует наше знание о вероятности того, что пробный образец принадлежит тому или иному классу. Мы предполагаем, что классы в галерее равновероятны, а out-of-gallery класс представлен непрерывным распределением. Таким образом, априорное распределение имеет вид:
\begin{equation}
p(c) = \frac{1 - \beta}{K} \sum_{i=1}^{K} \delta(c - i) + \beta I_{\{c \in (K, K+1]\}},
\label{eq:prior}
\end{equation}
где $\delta(\cdot)$ — дельта-функция Дирака, $I_{\{\cdot\}}$ — индикаторная функция, а $\beta$ — параметр, определяющий вероятность того, что пробный образец принадлежит out-of-gallery классу. Значение $\beta=0.5$ используется по умолчанию, так как оно обеспечивает баланс между галереей и out-of-gallery классами.

\subsection{Условное распределение эмбеддинга}
\label{subsec:conditional}

Условное распределение $p(z|c)$ моделирует, как эмбеддинги распределены вокруг центров классов. Для классов из галереи ($c \in \{1, ..., K\}$) мы используем распределение фон Мизеса-Фишера (vMF):
\begin{equation}
p(z|c) = C_d(\kappa) \exp(\kappa \mu_c^T z),
\label{eq:vmf}
\end{equation}
где $C_d(\kappa)$ — нормировочная константа, $\kappa$ — параметр концентрации (общий для всех классов), а $\mu_c$ — средний эмбеддинг класса $c$. Для out-of-gallery класса ($c \in (K, K+1]$) мы предполагаем, что эмбеддинги равномерно распределены по сфере, то есть:
\begin{equation}
p(z|c) = \delta(z - \mu_c^\circ),
\label{eq:out_of_gallery}
\end{equation}
где $\mu_c^\circ$ — эмбеддинг, соответствующий классу $c$, и $\mu_c^\circ$ равномерно распределен по сфере.

\subsection{Апостериорное распределение и мера неопределенности}
\label{subsec:posterior}

Подставив выражения для $p(c)$ и $p(z|c)$ в формулу Байеса (\ref{eq:bayes_rule}), мы можем вычислить апостериорное распределение $p(c|z)$. На основе этого распределения мы определяем меру неопределенности $q_{GalUE}$ как максимальную вероятность класса:
\begin{equation}
q_{GalUE}(z) = \max_{c \in \{0, ..., K\}} p(c|z),
\label{eq:galue}
\end{equation}
где $c=0$ соответствует out-of-gallery классу. Эта мера показывает, насколько уверенно система может отнести эмBEDдинг $z$ к одному из классов. Чем ниже значение $q_{GalUE}$, тем выше неопределенность.

\section{Метод SCF: Оценка неопределенности, связанной с качеством сигнала}
\label{sec:scf}

Метод \textit{SCF} (Spherical Confidence Face) — это подход, который позволяет оценить неопределенность, связанную с качеством входного сигнала. Этот метод предполагает, что эмBEDдинг $z$ является случайной величиной, распределенной по сфере, и использует вероятностную модель для его описания. В SCF эмBEDдинг $z$ моделируется как случайная величина, распределенная по распределению фон Мизеса-Фишера с параметрами $\mu(x)$ и $\kappa(x)$:
\begin{equation}
p(z|x) = C_d(\kappa(x)) \exp(\kappa(x) \mu(x)^T z),
\label{eq:scf}
\end{equation}
где $\mu(x)$ — средний эмBEDдинг сигнала $x$, а $\kappa(x)$ — параметр концентрации, который интерпретируется как мера качества сигнала. Чем выше значение $\kappa(x)$, тем более "острое" распределение, что указывает на высокое качество сигнала. Таким образом, мера неопределенности, связанной с качеством сигнала, определяется как:
\begin{equation}
q_{SCF}(x) = \kappa(x).
\label{eq:scf_quality}
\end{equation}

\section{Метод HolUE: Комплексная оценка неопределенности}
\label{sec:holue}

Метод \textit{HolUE} (Holistic Uncertainty Estimation) объединяет два источника неопределенности — неопределенность, связанную с качеством сигнала (метод SCF), и неопределенность, обусловленную структурой галереи (метод GalUE). Для этого мы используем интеграл, который позволяет вычислить апостериорное распределение классов $p(c|x)$, учитывая оба источника неопределенности:
\begin{equation}
p(c|x) = \int_{S^{d-1}} p(c|z) p(z|x) dz,
\label{eq:holue_integral}
\end{equation}
где $p(c|z)$ — апостериорное распределение классов, полученное с помощью метода GalUE, а $p(z|x)$ — распределение эмBEDдинга, полученное с помощью метода SCF.

Для оценки неопределенности мы используем расхождение Кулбака-Лейблера (KL-divergence) между апостериорным распределением $p(c|x)$ и априорным распределением $p(c)$:
\begin{equation}
D_{KL}(p(c|x) \| p(c)) = \sum_{c=1}^{K} p(c|x) \log \frac{p(c|x)}{p(c)} + \int_{K}^{K+1} p(c|x) \log \frac{p(c|x)}{p(c)} dc.
\label{eq:kl_divergence}
\end{equation}
Это расхождение показывает, насколько апостериорное распределение отличается от априорного. Чем больше значение KL-divergence, тем выше неопределенность.

Для численной стабильности и улучшения результатов мы применяем температурное масштабирование к апостериорному распределению:
\begin{equation}
p_T(c|x) = \frac{p(c|x)^{1/T}}{\sum_{c'} p(c'|x)^{1/T}},
\label{eq:temperature_scaling}
\end{equation}
где $T$ — температурный параметр (по умолчанию $T=20$).

Затем мы разделяем KL-divergence на две части: $KL1$, которая зависит от распределения классов, и $KL2$, которая зависит от распределения эмBEDдинга:
\begin{equation}
D_{KL}(p_T(c|x) \| p(c)) = KL1 + KL2.
\label{eq:kl_decomposition}
\end{equation}

Для окончательной калибровки мы используем многослойный перцептрон (MLP), который объединяет нормализованные значения $KL1$ и $KL2$ в единую меру неопределенности $q_{HolUE}$:
\begin{equation}
q_{HolUE} = f_\theta(KL1_{norm}, KL2_{norm}) \in [0, 1],
\label{eq:holue_final}
\end{equation}
где $f_\theta$ — MLP с параметрами $\theta$, обученный на валидационном наборе данных.

\section{Обсуждение и выводы}
\label{sec:theory_conclusion}

В этой главе мы подробно описали теоретические основы метода \textit{HolUE}. Мы показали, что HolUE — это первый метод, который объединяет два источника неопределенности в единую меру. Метод GalUE позволяет оценить неопределенность, обусловленную структурой галереи, а метод SCF — неопределенность, связанную с качеством сигнала. Объединение этих двух методов в единый фреймворк HolUE позволяет вычислять комплексную меру неопределенности, которая эффективно обнаруживает все три типа ошибок OSR: false acceptance, false rejection и misidentification.

Этот подход является доменно-агностичным и может быть применен в различных областях, таких как распознавание лиц, голоса и животных. В следующей главе мы опишем реализацию и эксперименты, подтверждающие эффективность нашего метода.
