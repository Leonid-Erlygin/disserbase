\textcolor{gray}{Глава 4 посвящена описанию экспериментальной методологии, использованной для всесторонней оценки предложенного метода HolUE и его компонентов GalUE и SCF.}  
\textcolor{blue}{Целью экспериментов является подтверждение гипотезы о том, что объединение информации о качестве входного сигнала и структуре галереи позволяет более эффективно детектировать ошибки распознавания в задаче открытого множества по сравнению с существующими подходами.}  
\textcolor{gray}{Для этого были отобраны четыре набора данных, охватывающих разные модальности: изображения лиц, аудиозаписи дикторов и фотографии морских млекопитающих.}  

\textcolor{blue}{В качестве основных наборов данных для модальности изображений использовались общепринятые бенчмарки IJB-B~\cite{ijbb} и IJB-C~\cite{ijbc}.}  
\textcolor{gray}{Эти наборы содержат в общей сложности десятки тысяч изображений и видеофрагментов, охватывающих более 3500 уникальных личностей, и характеризуются высокой вариативностью по качеству, ракурсу, освещению и наличию окклюзий.}  
\textcolor{red}{Для каждого из этих наборов был реализован стандартный протокол открытого распознавания: галерея формировалась из шаблонов лиц, а проб-запросы делились на «внутри-галерейные» (mated) и «вне-галерейные» (non-mated), последние использовались для моделирования неизвестных субъектов.}  

\textcolor{blue}{Для модальности аудио использовался набор данных VoxBlink~\cite{voxblink}, специально разработанный для задачи идентификации дикторов в условиях открытого множества.}  
\textcolor{gray}{В экспериментах применялся поднабор VB-Eval-Large-5, содержащий по пять речевых сэмплов на каждого диктора в галерее, что обеспечивает надёжную агрегацию эмбеддингов.}  
\textcolor{red}{Валидационное множество VB-Eval-Medium-5 использовалось для калибровки порогов и обучения постобрабатывающего MLP.}  

\textcolor{blue}{Для проверки обобщаемости метода за пределы биометрии человека был создан новый протокол на основе датасета Happywhale~\cite{whale}, который мы обозначаем как Whale.}  
\textcolor{gray}{Этот набор содержит 51\,033 изображения 15\,587 уникальных особей китов и дельфинов 30 различных видов.}  
\textcolor{red}{Протокол разделения на обучающую, валидационную и тестовую части был разработан нами специально для задачи OSR: идентичности, имеющие только одно изображение, рассматривались как вне-галерейные, а остальные случайным образом делились на шаблоны галереи и проб-запросы.}  

\textcolor{gray}{Во всех экспериментах в качестве базовой модели распознавания использовалась архитектура ArcFace~\cite{deng2019arcface}, обученная на датасете MS1MV2.}  
\textcolor{blue}{Для получения вероятностных эмбеддингов поверх ArcFace был дообучен головной модуль SCF~\cite{scf} в течение двух эпох на соответствующих обучающих подмножествах.}  
\textcolor{red}{Для оценки устойчивости к выбору backbone также были проведены дополнительные эксперименты с моделями CosFace~\cite{wang2018cosface} и HAAML~\cite{cao2025open}.}  

\textcolor{gray}{Процедура формирования галереи во всех случаях включала агрегацию эмбеддингов всех сэмплов одного субъекта путём усреднения, что соответствует стандартной практике в задачах распознавания по шаблону.}  
\textcolor{blue}{Эмбеддинги нормировались на единичной сфере $\mathbb{S}^{d-1}$, а расстояние между запросом и шаблоном вычислялось как косинусная близость.}  

\textcolor{gray}{Для оценки качества распознавания использовались общепринятые метрики:}  
\textcolor{blue}{— False Positive Identification Rate (FPIR) — доля вне-галерейных запросов, ошибочно принятых системой;}  
\textcolor{blue}{— False Negative Identification Rate (FNIR) — доля внутри-галерейных запросов, ошибочно отклонённых или неверно идентифицированных;}  
\textcolor{blue}{— F1-мера, сочетающая точность и полноту распознавания.}  
\textcolor{red}{Все метрики вычислялись при фиксированном уровне FPIR (0.01, 0.05, 0.1, 0.2), что позволяет сравнивать методы при одинаковом уровне безопасности.}  

\textcolor{gray}{Для оценки качества оценки неопределённости использовалась метрика Prediction Rejection Ratio (PRR)~\cite{malinin2017incorporating}.}  
\textcolor{blue}{PRR измеряет, насколько эффективно метод ранжирует ошибочные прогнозы: чем выше PRR, тем лучше система способна отфильтровать запросы, ведущие к ошибкам.}  
\textcolor{red}{Метрика нормирована относительно «оракула», который идеально отбрасывает все ошибки первым, и случайного фильтра, дающего PRR = 0. Значение PRR = 1 соответствует идеальному детектированию ошибок.}  

\textcolor{gray}{В качестве базовых методов для сравнения были выбраны:}  
\textcolor{blue}{— PFE~\cite{pfe}, использующий энтропию предсказанного гауссовского распределения как меру качества;}  
\textcolor{blue}{— SCF~\cite{scf}, использующий параметр концентрации $\kappa(x)$ как меру уверенности;}  
\textcolor{blue}{— ScaleFace~\cite{scaleface}, использующий предсказанную шкалу в функции потерь как прокси качества;}  
\textcolor{blue}{— AccScr~\cite{huber2022stating}, использующий расстояние скор-значения до порога принятия как меру неопределённости;}  
\textcolor{blue}{— GalUE, предложенный в Главе 2, оценивающий неопределённость на основе структуры галереи.}  
\textcolor{red}{Все методы оценивались в едином пайплайне без переобучения основной модели распознавания, что обеспечивает честное сравнение.}  

\textcolor{gray}{Для калибровки HolUE использовалось валидационное множество, полученное из MS1MV2 и Whale в соответствии с протоколами, описанными в Приложении F статьи.}  
\textcolor{blue}{На нём вычислялись статистики нормализации компонент KL-дивергенции ($\mu_i^{\text{val}}, \sigma_i^{\text{val}}$) и обучался MLP, решающий задачу бинарной классификации «ошибка / не ошибка» при заданном FPIR.}  
\textcolor{red}{Температура масштабирования $T = 20$ была выбрана эмпирически и показала устойчивую работу на всех наборах данных.}  

\textcolor{gray}{Таким образом, описанная экспериментальная методология обеспечивает всестороннюю и воспроизводимую оценку предложенного подхода в условиях, приближенных к реальным сценариям применения систем распознавания.}