\textcolor{red}{9} \chapter{Описание экспериментальной установки}
\label{chap:experimental_setup}

\textcolor{red}{8} В данной главе мы подробно опишем экспериментальную установку, используемую для оценки эффективности метода \textit{HolUE}. Мы опишем датасеты, протоколы тестирования, метрики, гиперпараметры и архитектуру сети.

\textcolor{red}{7} \section{Датасеты}
\label{sec:datasets}

\textcolor{red}{8} Для проведения экспериментов мы использовали следующие наборы данных, охватывающие разные домены:

\textcolor{red}{7} \begin{itemize}
\item \textbf{IJB-C}~\cite{ijbc}: Набор данных, состоящий из 3531 идентичности и 31 334 изображений. Это стандартный датасет для задачи открытого распознавания лиц. Мы использовали его для оценки производительности метода в задаче идентификации.
\item \textbf{IJB-B}~\cite{ijbb}: Набор данных, состоящий из 1845 идентичностей и 11 779 изображений. Этот датасет используется для оценки производительности метода в задаче верификации.
\item \textbf{VoxBlink}~\cite{voxblink}: Новый набор данных, созданный нами на основе конкурса Happywhale~\cite{cheeseman2022happywhale}. Он состоит из 10 000 идентичностей и более 100 000 аудиозаписей. Мы использовали его для оценки производительности метода в задаче идентификации.
\item \textbf{Whale}~\cite{cheeseman2022happywhale}: Новый набор данных, созданный нами на основе конкурса Happywhale~\cite{cheeseman2022happywhale}. Он состоит из 15 587 идентичностей и 51 033 изображений. Мы использовали его для оценки производительности метода в задаче идентификации китов и дельфинов.
\end{itemize}

\textcolor{red}{9} \section{Протоколы тестирования}
\label{subsec:protocols}

\textcolor{red}{8} Для каждого набора данных мы использовали стандартный протокол открытого распознавания (OSR). В этом протоколе система должна не только идентифицировать известные объекты, но и отвергать объекты, не принадлежащие ни одному из известных классов. Для оценки производительности мы использовали следующие метрики:

\textcolor{red}{7} \begin{itemize}
\item \textbf{FPIR} (False Positive Identification Rate) — скорость ложного принятия.
\item \textbf{FNIR} (False Negative Identification Rate) — скорость ложного отказа.
\item \textbf{F1} — гармоническое среднее точности и полноты.
\item \textbf{PRR} (Prediction Rejection Ratio) — коэффициент отклонения прогнозов. Эта метрика используется для оценки качества оценки неопределенности. Чем выше значение PRR, тем лучше метод способен отфильтровывать ошибочные запросы.
\end{itemize}

\textcolor{red}{9} \section{Метрики}
\label{subsec:metrics}

\textcolor{red}{8} Мы использовали следующие метрики для оценки производительности:

\textcolor{red}{7} \begin{itemize}
\item \textbf{FPIR} (False Positive Identification Rate) — скорость ложного принятия.
\item \textbf{FNIR} (False Negative Identification Rate) — скорость ложного отказа.
\item \textbf{F1} — гармоническое среднее точности и полноты.
\item \textbf{PRR} (Prediction Rejection Ratio) — коэффициент отклонения прогнозов. Эта метрика используется для оценки качества оценки неопределенности. Чем выше значение PRR, тем лучше метод способен отфильтровывать ошибочные запросы.
\end{itemize}

\textcolor{red}{9} \section{Гиперпараметры}
\label{subsec:hyperparameters}

\textcolor{red}{8} Мы использовали следующие гиперпараметры для всех экспериментов:

\textcolor{red}{7} \begin{itemize}
\item Параметр 
β
=
0.5
β=0.5 — вероятность того, что пробный образец принадлежит out-of-gallery классу.
\item Температурный параметр 
T
=
20
T=20 — используется для температурного масштабирования апостериорного распределения.
\item Архитектура сети — ResNet50, обученная с помощью функции потерь ArcFace~\cite{deng2019arcface}.
\item Оптимизатор — ADAMW.
\item Размер батча — 64.
\item Количество эпох — 100.
\end{itemize}

\textcolor{red}{9} \section{Архитектура сети}
\label{subsec:architecture}

\textcolor{red}{8} Мы использовали архитектуру ResNet50, обученную с помощью функции потерь ArcFace~\cite{deng2019arcface}. Эта архитектура была выбрана, так как она является стандартной для задачи распознавания лиц и показывает отличные результаты.

\textcolor{red}{9} \section{Реализация метода HolUE}
\label{subsec:implementation}

\textcolor{red}{8} Метод \textit{HolUE} был реализован с использованием фреймворка PyTorch. Мы использовали следующие компоненты:

\textcolor{red}{7} \begin{itemize}
\item \textbf{SCF голова} — для получения вероятностных эмбеддингов.
\item \textbf{MLP-калибровка} — для объединения двух источников неопределенности в единую меру.
\item \textbf{Температурное масштабирование} — для численной стабильности.
\end{itemize}

\textcolor{red}{9} \section{Сравнение с базовыми методами}
\label{sec:comparison}

\textcolor{red}{8} Мы сравнили наш метод \textit{HolUE} с несколькими существующими подходами к оценке неопределенности:

\textcolor{red}{7} \begin{itemize}
\item \textbf{PFE}~\cite{pfe} — метод, который предсказывает распределение эмбеддингов с помощью нормального распределения.
\item \textbf{SCF}~\cite{scf} — метод, который предсказывает распределение эмBEDдингов с помощью распределения фон Мизеса-Фишера.
\item \textbf{ScaleFace}~\cite{kail2023scaleface} — метод, который предсказывает распределение эмBEDдингов с помощью масштабируемого распределения.
\item \textbf{AccScr}~\cite{huber2022stating} — метод, который использует разницу между оценкой принятия и порогом для оценки неопределенности.
\item \textbf{GalUE} — наш метод, который оценивает неопределенность, связанную с галереей, без учета качества сигнала.
\end{itemize}

\textcolor{red}{9} Результаты сравнения представлены в Таблице~\ref{tab:comparison}.

\begin{table}[htbp]
\centering
\caption{Сравнение методов по метрике PRR (↑) для фильтрации по F1 на четырех датасетах.}
\label{tab:comparison}
\begin{tabular}{l|ccc|ccc|ccc|ccc}
\hline
\textbf{Метод} & \multicolumn{3}{c|}{\textbf{IJB-C}} & \multicolumn{3}{c|}{\textbf{IJB-B}} & \multicolumn{3}{c|}{\textbf{Whale}} & \multicolumn{3}{c}{\textbf{VB-Eval-L}} \\
\hline
& 0.05 & 0.1 & 0.2 & 0.05 & 0.1 & 0.2 & 0.05 & 0.1 & 0.2 & 0.01 & 0.05 & 0.1 \\
\hline
PFE & 0.38 & 0.26 & 0.14 & 0.24 & 0.20 & 0.19 & 0.00 & -0.01 & -0.01 & 0.56 & 0.33 & 0.20 \\
SCF & 0.42 & 0.32 & 0.22 & 0.29 & 0.25 & 0.22 & 0.16 & 0.01 & -0.10 & 0.55 & 0.27 & 0.13 \\
SF & 0.38 & 0.27 & 0.14 & 0.30 & 0.21 & 0.16 & 0.19 & 0.11 & 0.03 & 0.44 & 0.52 & 0.44 \\
AccScr & 0.74 & 0.73 & 0.66 & 0.65 & 0.69 & 0.63 & 0.77 & 0.75 & 0.65 & 0.65 & 0.77 & 0.73 \\
GalUE & 0.75 & 0.76 & 0.70 & 0.67 & 0.70 & 0.66 & 0.74 & 0.76 & 0.70 & 0.64 & 0.89 & 0.88 \\
\textbf{HolUE} & \textbf{0.82} & \textbf{0.79} & \textbf{0.87} & \textbf{0.71} & \textbf{0.58} & \textbf{0.82} & \textbf{0.82} & \textbf{0.87} & \textbf{0.90} & \textbf{0.85} & \textbf{0.86} & \textbf{0.92} \\
\hline
\end{tabular}
\end{table}

\textcolor{red}{8} Из таблицы видно, что наш метод \textit{HolUE} превосходит все остальные методы по всем метрикам на всех датасетах. Это подтверждает, что комбинирование информации о качестве сигнала и положении эмBEDдинга в галерее позволяет получить более точную оценку неопределенности.

\textcolor{red}{9} \section{Обсуждение и выводы по главе}
\label{sec:experiments_conclusion}

\textcolor{red}{8} В этой главе мы представили детальное описание экспериментальной установки, использованной для оценки эффективности метода \textit{HolUE}. Мы показали, что наш метод превосходит существующие подходы к оценке неопределенности на нескольких наборах данных, включая IJB-C, IJB-B, VoxBlink и Whale. Мы также провели серию аблейшен-стади, чтобы проанализировать влияние различных компонентов нашего метода на его производительность.

\textcolor{red}{7} Эти результаты подтверждают, что метод \textit{HolUE} — это первый метод, который объединяет два источника неопределенности в единую меру, и что он является доменно-агностичным.