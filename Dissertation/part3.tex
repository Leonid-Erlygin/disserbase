\textcolor{green}{Глава 3 посвящена разработке комплексной байесовской модели оценки неопределённости в задаче открытого распознавания, объединяющей информацию о качестве входного сигнала и структуре галереи известных объектов.}  
\textcolor{blue}{Предлагаемый в этой главе метод HolUE (Holistic Uncertainty Estimation) расширяет модель GalUE, представленную в Главе 2, за счёт учёта вероятностной природы эмбеддинга запроса, что позволяет детектировать все три типа ошибок OSR: ложное принятие (false acceptance), ложный отказ (false rejection) и ошибочную идентификацию (misidentification).}  
\textcolor{green}{Основная идея метода заключается в моделировании апостериорного распределения классов \(p(c \mid x)\) через интеграл по пространству эмбеддингов, что формально объединяет обе составляющие неопределённости в единую меру.}  

\textcolor{blue}{Рассмотрим биометрический запрос \(x\), представленный одним или несколькими образцами (например, изображением лица или аудиозаписью голоса).}  
\textcolor{green}{В отличие от детерминированного подхода, используемого в GalUE, HolUE предполагает, что \(x\) порождает не фиксированный эмбеддинг \(z\), а распределение \(p(z \mid x)\) в признаковом пространстве \(\mathbb{S}^{d-1}\).}  
\textcolor{red}{Это распределение кодирует неопределённость, связанную с качеством входного сигнала: например, при размытом изображении или зашумлённой аудиозаписи дисперсия распределения будет высокой, что отражает низкое доверие к полученному эмбеддингу.}  

\textcolor{green}{Апостериорное распределение классов вычисляется по формуле полной вероятности:}  
\textcolor{green}{\[
p(c \mid x) = \int_{\mathbb{S}^{d-1}} p(c \mid z) \, p(z \mid x) \, dz,
\]}  
\textcolor{blue}{где \(p(c \mid z)\) — галерею-осознанное распределение, определённое в Главе 2, а \(p(z \mid x)\) — вероятностный эмбеддинг, предсказываемый, например, моделью SCF~\cite{li2021spherical}.}  
\textcolor{red}{Точное вычисление этого интеграла аналитически невозможно, поэтому в работе используется приближение, основанное на замене распределения \(p(z \mid x)\) его средним значением \(\mu_x = \mathbb{E}_{z \sim p(z \mid x)}[z]\).}  

\textcolor{green}{Для моделирования \(p(z \mid x)\) используется распределение фон Мизеса–Фишера с параметрами \(\mu(x)\) и \(\kappa(x)\), предсказываемыми нейросетью:}  
\textcolor{green}{\[
p(z \mid x) = C_d(\kappa(x)) \exp\left(\kappa(x) \, \mu(x)^\top z\right).
\]}  
\textcolor{blue}{Здесь \(\kappa(x) > 0\) — параметр концентрации, обратно пропорциональный дисперсии: чем выше \(\kappa(x)\), тем выше качество входного сигнала.}  
\textcolor{red}{Такой выбор позволяет использовать хорошо изученные свойства vMF-распределений и совместим с существующими архитектурами, такими как SCF.}  

\textcolor{green}{Подставляя приближение \(p(c \mid x) \approx p(c \mid \mu_x)\) в выражение для апостериорного распределения, получаем оценку, сочетающую информацию из обеих моделей.}  
\textcolor{blue}{Для количественной оценки степени неопределённости предлагается использовать расхождение Кулбака–Лейблера (KL-дивергенцию) между апостериорным распределением \(p(c \mid x)\) и априорным распределением \(p(c)\):}  
\textcolor{green}{\[
\mathcal{U}(x) = D_{\mathrm{KL}}\!\left( p(c \mid x) \,\|\, p(c) \right).
\]}  
\textcolor{red}{Эта мера достигает максимума, когда апостериорное распределение близко к равномерному (высокая неопределённость), и минимума — когда оно сосредоточено на одном классе (высокая уверенность).}  

\textcolor{green}{Для обеспечения числовой устойчивости и балансировки вкладов от разных источников неопределённости применяется температурное масштабирование апостериорных вероятностей.}  
\textcolor{blue}{KL-дивергенция разделяется на две компоненты:}  
\textcolor{green}{\[
\mathcal{U}(x) = \underbrace{\sum_{c=1}^K P_T(c \mid x) \log \frac{P_T(c \mid x)}{P(c)}}_{\text{KL}_1} + \underbrace{\frac{\beta^{1/T}}{S_{d-1}^{1/T}} \frac{1}{p(\mu_x)} \log\!\left[ \left(\frac{\beta}{S_{d-1}}\right)^{1/T - 1} \frac{p(\mu_x \mid x)}{p(\mu_x)} \right]}_{\text{KL}_2},
\]}  
\textcolor{red}{где \(\text{KL}_1\) отражает галерею-осознанную неопределённость (аналог GalUE), а \(\text{KL}_2\) — неопределённость, связанную с качеством сигнала (аналог SCF).}  

\textcolor{green}{Обе компоненты нормализуются по статистикам, полученным на валидационном множестве:}  
\textcolor{green}{\[
\text{KL}^{\text{norm}}_i = \frac{\text{KL}_i - \mu_i^{\text{val}}}{\sigma_i^{\text{val}}}, \quad i \in \{1, 2\},
\]}  
\textcolor{blue}{где \(\mu_i^{\text{val}}\) и \(\sigma_i^{\text{val}}\) — выборочные среднее и стандартное отклонение компоненты \(\text{KL}_i\) на валидации.}  
\textcolor{red}{Такая нормализация устраняет различия в масштабах между компонентами и делает их сопоставимыми.}  

\textcolor{green}{Для финальной калибровки и получения итоговой оценки достоверности \(q_{\text{HolUE}}(x) \in [0,1]\) применяется многослойный перцептрон (MLP), обученный на валидационном множестве.}  
\textcolor{blue}{MLP решает бинарную задачу классификации: предсказать, приведёт ли данный запрос к ошибке распознавания при фиксированном уровне ложных срабатываний (FPIR).}  
\textcolor{red}{Альтернативно, вместо MLP может использоваться параметрическая функция на основе сигмоиды и экспоненциальных преобразований, однако эксперименты показали, что MLP обеспечивает наилучшее качество.}  

\textcolor{green}{Таким образом, метод HolUE предоставляет теоретически обоснованную, доменно-агностичную и практически эффективную оценку неопределённости, способную детектировать все типы ошибок в задаче открытого распознавания.}  
\textcolor{blue}{Алгоритм HolUE не требует переобучения базовой модели распознавания и может быть применён пост-фактум к любому системному пайплайну, использующему угловые эмбеддинги.}  
\textcolor{red}{Дальнейшая Глава 4 посвящена описанию экспериментальной методологии, использованной для верификации эффективности предложенного подхода.}